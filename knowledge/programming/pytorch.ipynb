{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensor Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize random 5x3 matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix filled zeros and of dtype long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5.5, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a torch tensor to NumPy Array and vice versa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = x.numpy()\n",
    "x = torch.from_numpy(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7028,  0.1901],\n",
      "         [ 1.7985, -0.2737],\n",
      "         [ 0.4400, -0.8318],\n",
      "         [-0.8569,  2.2270],\n",
      "         [ 1.3089,  0.1994],\n",
      "         [ 0.0693,  0.3087],\n",
      "         [ 0.0447, -0.0729]],\n",
      "\n",
      "        [[ 0.2017, -0.4898],\n",
      "         [-0.3361,  0.4311],\n",
      "         [-0.0747, -0.0776],\n",
      "         [-1.3892,  0.5870],\n",
      "         [ 1.7291, -0.6484],\n",
      "         [ 0.6536, -1.0552],\n",
      "         [ 1.4439, -1.0526]],\n",
      "\n",
      "        [[-0.8398, -1.0046],\n",
      "         [-1.5248, -0.8343],\n",
      "         [-2.7795,  1.4313],\n",
      "         [-0.2373, -0.3244],\n",
      "         [ 0.3934, -0.5255],\n",
      "         [ 0.9037, -0.0034],\n",
      "         [ 1.9146,  1.7218]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 7, 2, dtype=torch.double)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maße des Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 2])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.size(0)) # Size of 0. (1.) Dimension == Number of Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1901, -0.2737, -0.8318,  2.2270,  0.1994,  0.3087, -0.0729],\n",
      "        [-0.4898,  0.4311, -0.0776,  0.5870, -0.6484, -1.0552, -1.0526],\n",
      "        [-1.0046, -0.8343,  1.4313, -0.3244, -0.5255, -0.0034,  1.7218]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = x[:,:,1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7467, -2.3054,  0.4609], dtype=torch.float64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(input=y, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze Tensor\n",
    "- Squeezing a tensor removes the dimensions or axes that have a length of one.\n",
    "- Unsqueezing a tensor adds a dimension with a length of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.5300e-01],\n",
      "         [ 2.4879e+00],\n",
      "         [ 7.7723e-04]],\n",
      "\n",
      "        [[ 2.5263e-01],\n",
      "         [-2.1398e+00],\n",
      "         [ 7.5477e-02]],\n",
      "\n",
      "        [[ 1.4362e+00],\n",
      "         [ 3.9126e-01],\n",
      "         [-6.1167e-01]],\n",
      "\n",
      "        [[ 7.9002e-01],\n",
      "         [-7.8850e-01],\n",
      "         [-2.1712e+00]],\n",
      "\n",
      "        [[-8.5125e-01],\n",
      "         [ 3.6094e-01],\n",
      "         [-9.9632e-01]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "-------------------\n",
      "torch.Size([5, 3])\n",
      "tensor([[ 9.5300e-01,  2.4879e+00,  7.7723e-04],\n",
      "        [ 2.5263e-01, -2.1398e+00,  7.5477e-02],\n",
      "        [ 1.4362e+00,  3.9126e-01, -6.1167e-01],\n",
      "        [ 7.9002e-01, -7.8850e-01, -2.1712e+00],\n",
      "        [-8.5125e-01,  3.6094e-01, -9.9632e-01]], dtype=torch.float64)\n",
      "-------------------\n",
      "torch.Size([5, 3, 1])\n",
      "tensor([[[ 9.5300e-01],\n",
      "         [ 2.4879e+00],\n",
      "         [ 7.7723e-04]],\n",
      "\n",
      "        [[ 2.5263e-01],\n",
      "         [-2.1398e+00],\n",
      "         [ 7.5477e-02]],\n",
      "\n",
      "        [[ 1.4362e+00],\n",
      "         [ 3.9126e-01],\n",
      "         [-6.1167e-01]],\n",
      "\n",
      "        [[ 7.9002e-01],\n",
      "         [-7.8850e-01],\n",
      "         [-2.1712e+00]],\n",
      "\n",
      "        [[-8.5125e-01],\n",
      "         [ 3.6094e-01],\n",
      "         [-9.9632e-01]]], dtype=torch.float64)\n",
      "-------------------\n",
      "torch.Size([5, 1, 3])\n",
      "tensor([[[ 9.5300e-01,  2.4879e+00,  7.7723e-04]],\n",
      "\n",
      "        [[ 2.5263e-01, -2.1398e+00,  7.5477e-02]],\n",
      "\n",
      "        [[ 1.4362e+00,  3.9126e-01, -6.1167e-01]],\n",
      "\n",
      "        [[ 7.9002e-01, -7.8850e-01, -2.1712e+00]],\n",
      "\n",
      "        [[-8.5125e-01,  3.6094e-01, -9.9632e-01]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 5 = 0. Dimension; 3 = 1. Dimension; 1 = 2. Dimension\n",
    "x = torch.randn(5, 3, 1, dtype=torch.double)\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(\"-------------------\")\n",
    "y = torch.squeeze(x)\n",
    "print(y.size())\n",
    "print(y)\n",
    "print(\"-------------------\")\n",
    "y_1 = torch.unsqueeze(y, dim=2) # Add a new dimension on the 2. place \n",
    "print(y_1.size())\n",
    "print(y_1)\n",
    "print(\"-------------------\")\n",
    "y_2 = torch.unsqueeze(y, dim=1) # Add a new dimension on the 2. place \n",
    "print(y_2.size())\n",
    "print(y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape tensor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4) # 4x4\n",
    "y = x.view(16) # 1x16\n",
    "z = x.view(-1, 8) # 2x8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grundoperationen von Tensoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "z = x + y # Add x and y element wise\n",
    "z = x * y # Multiply x and y element wise \n",
    "z = x + 2 # Add 2 to every element of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is like in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Computational graph\n",
    "It abstracts the complicated mathematics and helps us “magically” calculate gradients of high dimensional curves with only a few lines of code. On setting ``<Tensor>.requires_grad = True`` tensors start forming a backward graph that tracks every operation applied on them. <br>\n",
    "The autograd class is an engine to calculate derivatives (Jacobian-vector product to be more precise). It records a graph of all the operations performed on a gradient enabled tensor and creates an acyclic graph called the dynamic computational graph. <br>\n",
    "The leaves of this graph are input tensors and the roots are output tensors. Gradients are calculated by tracing the graph from the root to the leaf and multiplying every gradient in the way using the chain rule. <br>\n",
    "Gradient enabled tensors (variables) along with functions (operations) combine to create the dynamic computational graph. The flow of data and the operations applied to the data are defined at runtime hence constructing the computational graph dynamically. <br>\n",
    "Each tensor has a `.grad_fn attribute` that references a Function that has created the Tensor (except for Tensors created by the user - their grad_fn is None). <br>\n",
    "If you want to compute the derivatives, you can call `.backward()` on a Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PyTorch terminology\n",
    "## Variable \n",
    "A wrapper around tensor is created called Variable to store more properties. <br>\n",
    "Variable have certain properties:\n",
    "- .data (the tensor under the variable) \n",
    "- .grad (the gradient computed for this variable, must be of the same shape and type of .data), \n",
    "- .requires_grad (boolean indicating whether to calculate gradient for the Variable during backpropagation)\n",
    "- .grad_fn (the function that created this Variable, used when backproping the gradients).\n",
    "- .volatile, whose function will be explained later on. \n",
    "\n",
    "Variable is available under `torch.autograd.Variable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter\n",
    "Parameter is a subclass of Variable so most behaviors are the same.\n",
    "The most important difference is that if you use `nn.Parameter` in a `nn.Module's` constructor, it will be added into the modules parameters just like nn.Module object do. Here is an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.variable = torch.autograd.Variable(torch.Tensor([5]))\n",
    "        self.parameter = torch.nn.Parameter(torch.Tensor([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das bedeutet ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "These transforms the input using some operation. These do not store any state or buffer, so, have no memory of their own and are completely predictable. A log function will give log value output of its inputs. Whereas, a linear layer cannot be a function, since it have internal states such as weights and biases. <br>\n",
    "Whenever we need to create a new function we will create a subclass and inherit from `torch.autograd.Function`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n",
    "In modules we can club our parameters, layers and functions. Whenever, we are backproping we will compute gradients for parameters of the module and child modules recursively.\n",
    "Predefined modules are implemented under `torch.nn` as `torch.nn.Conv2d`, `torch.nn.Linear` etc. <br>\n",
    "Whenever we need to define a new model (module) we will create a subclass and inherit from `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it inside the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Layer Typs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 5) #in_channels, out_channels, kernel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully Connected Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(120, 84) #120 features in; 84 features out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Functions\n",
    "- Input of a function is its in front tensor and the input of this tensor is the previous x: `x = F.relu(self.fc1(x))`\n",
    "- You can nest functions: `x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples:<br>\n",
    "F.relu() <br>\n",
    "F.dorpout() <br>\n",
    "F.log_softmax() <br>\n",
    "F.elu() <br>\n",
    "F.sigmoid() <br>\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights of each Layer\n",
    "You can access weights of each layer which is defined in your network: `network.conv1.weights`. <br>\n",
    "The layer weigth shape is accessable like this: `network.conv1.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build and Train Neural Network\n",
    "## Define NN via Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8fdf28f763b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# inside __init__() you define the different layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeinNetz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    # inside __init__() you define the different layers\n",
    "    def __init__(self):\n",
    "        super(MeinNetz, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    # inside forward() you define the sequence of functions\n",
    "    # input of a function is its in front tensor and the input of this tensor is the previous x\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # you can nest functions\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size[1:]\n",
    "        num = 1\n",
    "        for i in size:\n",
    "            num *= i\n",
    "        return num\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Network, Define Input and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(10,10)) # 10x datapoints with 10 features\n",
    "target = Variable(torch.Tensor([[0,1,1,1,0,1,1,1,0,0] for _ in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss-function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(netz.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    out = neural_network(input)\n",
    "    loss = loss_fn(out, target) # 2 parameters: 1x networks prediction and 1x true value\n",
    "    hist[t] = loss.item()\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Use grafic card\n",
    "First you have to execute the `.cuda()` function on the initialized network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = Network()\n",
    "neural_network = neural_network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second you have to execute the `.cuda()` function on every Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.Tensor([1,0,0,0,0,0,1,0,1]))\n",
    "input = input.cuda()\n",
    "target = Variable(torch.Tensor([1,0,0,0,0,0,1,0,1]))\n",
    "target = target.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Save and load neuornal network\n",
    "## Save:\n",
    "When saving a model for inference, it is only necessary to save the trained model’s learned parameters. A common PyTorch convention is to save models using `.pt` file extension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neural_network.state_dict(), \"<path>/neural_network.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load:\n",
    "Remember that you must call `model.eval()` to set the network to evaluation mode before running predictions with the neural network. By default all the modules are initialized to train mode (self.training = True). Because some layers have different behavior during train/and evaluation (like Dropout, etc.) it matters to set `.eval()` to change the net to evaluation (prediction) mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = TheModelClass(*args, **kwargs) # Enter name of defined class for that network\n",
    "neural_network.load_state_dict(torch.load(\"<path>/neural_network.pt\")\n",
    "neural_network.eval()                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading a Checkpoint:\n",
    "Deep learning models can take hours, days or even weeks to train. If the run is stopped unexpectedly, you can lose a lot of work. Application Checkpoint is a fault tolerance technique for long running processes. <br>\n",
    "__Save__: <br>\n",
    "When saving a general checkpoint, to be used for resuming training, you must save more than just the model’s state_dict. It is important to also save the optimizer’s state_dict, as this contains buffers and parameters that are updated as the model trains. You can save any other items (like loss) that may aid you in resuming training by simply appending them to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, \"<path>/neural_network.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load__: <br>\n",
    "To load the models, first initialize the models __and__ optimizers, then load the dictionary locally using torch.load(). From here, you can easily access the saved items by simply querying the dictionary as you would expect. <br>\n",
    "Remember that you must call `model.train()` to set the network to training mode before train the neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs) # Enter name of defined class for that network\n",
    "optimizer = TheOptimizerClass(*args, **kwargs) # Enter name of defined class for the optimizer\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Data Loader\n",
    "Dataset and Data loaders are the tools in PyTorch can define how to access your data. This is specially interesting when your data is distributed over several files. For instance, if you have several images in some directory structure, you can personalize the way you access it with the Dataset class.\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods: \n",
    "- init: In the initialization, you should put your directories information and other things that would allow to access it.\n",
    "- len: In this method, you should implement a way to get the entire size of your dataset. For instance, if you have a set of images in some directories, you have to implement a way of counting the total number of files that makes your data. In my basic example, I simply get the length of my dataframe.\n",
    "- getitem: This is where you implement how to get a single item from your dataset. For instance, if you have several images, here is wher\n",
    "\n",
    "This is memory efficient because all the images are not stored in the memory at once but read as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ExampleDataset(Dataset):\n",
    "    \"\"\"Example Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\" \n",
    "        csv_file (string): Path to the csv file containing data.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_frame[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExampleDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-532e5e6c23b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# instantiates the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexample_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExampleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_data_file.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# batch size: number of samples returned per iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# shuffle: Flag to shuffle the data before reading so you don't read always in the same order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ExampleDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# instantiates the dataset  \n",
    "example_dataset = ExampleDataset('my_data_file.csv')\n",
    "\n",
    "# batch size: number of samples returned per iteration\n",
    "# shuffle: Flag to shuffle the data before reading so you don't read always in the same order\n",
    "# num_workers: used to load the data in parallel\n",
    "example_data_loader = DataLoader(example_dataset, batch_size=4, num_workers=4)\n",
    "\n",
    "# Loops over the data 4 samples at a time\n",
    "for batch_index, batch in enumerate(example_data_loader):\n",
    "    print(batch_index, batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
