{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# own Modules \n",
    "from models.models import LstmMseDropout\n",
    "from utils.data_loader import DataPreperatorPrediction, DataSet\n",
    "from loss_module import LossModuleMse, LossModuleMle\n",
    "from utils.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"data\" : {\n",
    "        \"stake_training_data\" : 0.75, \n",
    "        \"path\" : '../../data/artifical_signals/NewBlade_random_walk_time_difference.csv',\n",
    "        \"droped_feature\" : [\"timestamp\"]\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"path\" : \"../../models/MSE_model/random_walk_time_difference_InputSize7_LayerLstm2_HiddenLstm200_HiddenFc75_Seq100.pt\",\n",
    "        \"input_size\" : 7,\n",
    "        \"n_hidden_lstm\" : 200,\n",
    "        \"sequence_size\" : 100,\n",
    "        \"batch_size\" : 1,  # Has to be 1 in prediction mode!!!\n",
    "        \"lstm_layer\" : 2,\n",
    "        \"n_hidden_fc\": 75,\n",
    "        \"dropout_rate\": 0.2\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"path_prediction\" : \"../visualisation/files/prediction/random_walk_difference.csv\",\n",
    "        \"path_residual\" : \"../visualisation/files/residuals/random_walk_difference.csv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarize Data\n",
    "First we have to apply normalisation to data. That is because the model works on the representation given by its input vectors. The scale of those numbers is part of the representation.\n",
    "We should apply the exact same scaling as for training data. That means storing the scale and offset used with your training data, and using that again. <br>\n",
    "__The mean and variance for each feature of the training data with which the model was trained (stake: 0.75):__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from NewBlade Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data = [-5.37536613e-02, -2.53111489e-04, -8.82854465e+05, 7.79034183e+02, 1.45531178e+04, 1.37766733e+03, 6.50149764e-01] \n",
    "var_training_data = [1.25303578e-01, 1.16898690e-03, 2.86060835e+06, 1.64515717e+06, 6.85728371e+06, 3.63196175e+05, 8.21463343e-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from Artifical Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data= [-5.31764899e-02, -3.98576146e-04, -8.82773455e+05,  8.25672897e+02, 1.47034247e+04,  1.42685595e+03,  6.62155736e-01,  1.23172374e-02]\n",
    "var_training_data = [1.28792583e-01, 1.21258617e-03, 2.90245238e+06, 1.72279458e+06, 6.83095901e+06, 3.12357562e+05, 3.89033076e-03, 5.01164766e+01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from Random Walk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data =[-5.31764899e-02, -3.98576146e-04,  1.55255733e+03,  8.25672897e+02, 1.47034247e+04,  1.42685595e+03,  6.62155736e-01]\n",
    "var_training_data =[1.28792583e-01, 1.21258617e-03, 2.04108811e+06, 1.72279458e+06, 6.83095901e+06, 3.12357562e+05, 3.89033076e-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from Random Walk Data with first order difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data =[-5.30145478e-02, -3.98852220e-04,  1.57238159e+00,  8.26196229e+02, 1.47058099e+04,  1.42778443e+03,  6.62286323e-01]\n",
    "var_training_data =[1.28839165e-01, 1.21339499e-03, 1.10982448e+03, 1.72353307e+06, 6.82698220e+06, 3.11272820e+05, 3.86734667e-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timestamp   cut torque   cut lag error   cut position   cut speed  \\\n",
      "0      0.008    -0.283251       -0.006468            0.0   48.065186   \n",
      "1      0.012    -0.308639        0.000107            0.0   44.631958   \n",
      "2      0.016    -0.331372        0.004387            1.0   51.498413   \n",
      "3      0.020    -0.346761        0.004063            0.0   65.231323   \n",
      "4      0.024    -0.297286       -0.014619            0.0   72.097778   \n",
      "\n",
      "    film position   film speed   film lag error  \n",
      "0           11128    32.556355         0.491569  \n",
      "1           11128    40.069519         0.519276  \n",
      "2           11129    45.078098         0.545538  \n",
      "3           11129    52.591114         0.561331  \n",
      "4           11129    57.599842         0.574634  \n",
      "    cut torque   cut lag error   cut position   cut speed   film position  \\\n",
      "0    -0.283251       -0.006468            0.0   48.065186           11128   \n",
      "1    -0.308639        0.000107            0.0   44.631958           11128   \n",
      "2    -0.331372        0.004387            1.0   51.498413           11129   \n",
      "3    -0.346761        0.004063            0.0   65.231323           11129   \n",
      "4    -0.297286       -0.014619            0.0   72.097778           11129   \n",
      "\n",
      "    film speed   film lag error  \n",
      "0    32.556355         0.491569  \n",
      "1    40.069519         0.519276  \n",
      "2    45.078098         0.545538  \n",
      "3    52.591114         0.561331  \n",
      "4    57.599842         0.574634  \n"
     ]
    }
   ],
   "source": [
    "data_preperator = DataPreperatorPrediction(path=param['data']['path'], \n",
    "                                           ignored_features = param[\"data\"][\"droped_feature\"],\n",
    "                                           mean_training_data=mean_training_data, \n",
    "                                           var_training_data=var_training_data, \n",
    "                                           first_order_difference=False \n",
    "                                          )                                  \n",
    "preprocessed_data = data_preperator.prepare_data()\n",
    "\n",
    "dataset = DataSet(preprocessed_data, \n",
    "                  timesteps=param[\"model\"][\"sequence_size\"])\n",
    "data_loader = DataLoader(dataset, \n",
    "                         batch_size=param['model']['batch_size'], \n",
    "                         num_workers=1, \n",
    "                         shuffle=False, \n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and load Parameters of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LstmMseDropout(batch_size=param['model']['batch_size'], \n",
    "                       input_dim=param['model']['input_size'], \n",
    "                       n_hidden_lstm=param['model']['n_hidden_lstm'], \n",
    "                       n_hidden_fc=param['model']['n_hidden_fc'], \n",
    "                       n_layers=param['model']['lstm_layer'], \n",
    "                       dropout_rate= param['model']['dropout_rate'])\n",
    "\n",
    "checkpoint = torch.load(param[\"model\"][\"path\"])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LossModuleMse(param[\"model\"][\"input_size\"], param[\"model\"][\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(model=model,\n",
    "                      criterion=criterion,\n",
    "                      path_data=param[\"data\"][\"path\"],\n",
    "                      path_results=param[\"results\"][\"path_prediction\"],\n",
    "                      path_residuals=param[\"results\"][\"path_residual\"],\n",
    "                      columns_to_ignore=param[\"data\"][\"droped_feature\"]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n",
      "Finished predicting\n"
     ]
    }
   ],
   "source": [
    "results = predictor.predict(data_loader)\n",
    "predictor.save_prediction(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Residuals for New Blade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = predictor.compute_residuals(results)\n",
    "predictor.save_residuals(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
