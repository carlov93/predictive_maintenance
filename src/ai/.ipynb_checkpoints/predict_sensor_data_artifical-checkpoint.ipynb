{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# own Modules \n",
    "from models_mse import LstmMse\n",
    "from models_mle import LstmMle_1\n",
    "from models_sub_net_ls import LstmMse_LatentSpace\n",
    "from data_preperator import DataPreperatorPrediction\n",
    "from data_set import DataSet\n",
    "from predictor import PredictorMse\n",
    "from predictor import PredictorMle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take care of these things before training:\n",
    "- Select correct path and define droped_features\n",
    "- Change parameter of model\n",
    "- Change filed_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"data\" : {\n",
    "        \"path\" : '../../data/phm_data_challenge/01_M01_DC_prediction_1.csv',\n",
    "        \"droped_feature\" : [\"stage\", \"Lot\", \"runnum\", \"recipe\", \"recipe_step\",\n",
    "                            \"up time\", \"ongoing time\", \n",
    "                            \"ETCHSOURCEUSAGE\", \"ETCHAUXSOURCETIMER\", \n",
    "                            \"ETCHAUX2SOURCETIMER\", \"FIXTURESHUTTERPOSITION\"\n",
    "                           ],\n",
    "        \"features_not_to_scale\": []\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"path\" : \"../../models/MLE_model/phm_dataFold xx_InputSize13_LayerLstm1_HiddenLstm15_HiddenFc75_Seq25.pt\",\n",
    "        \"input_size\" : 13,\n",
    "        \"n_hidden_lstm\" : 15,\n",
    "        \"n_hidden_fc\" : 75,\n",
    "        \"sequence_size\" : 100,\n",
    "        \"batch_size\" : 50,\n",
    "        \"lstm_layer\" : 1,\n",
    "        \"dropout_rate_lstm\": 0.0,\n",
    "        \"dropout_rate_fc\": 0.2,\n",
    "        \"K\":1\n",
    "    },\n",
    "        \"anomaly_detection\" : {\n",
    "        \"threshold_anomaly\" : 0.3,\n",
    "        \"smooth_rate\" : 0.05,\n",
    "        \"no_standard_deviation\" : 2\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"path\" : \"../visualisation/files/prediction/phm_mle_1.csv\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarize Data\n",
    "First we have to apply normalisation to data. That is because the model works on the representation given by its input vectors. The scale of those numbers is part of the representation.\n",
    "We should apply the exact same scaling as for training data. That means storing the scale and offset used with your training data, and using that again. <br>\n",
    "__The mean and variance for each feature of the training data with which the model was trained (stake: 0.75):__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from NewBlade Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data = [-5.37536613e-02, -2.53111489e-04, -8.82854465e+05, 7.79034183e+02, 1.45531178e+04, 1.37766733e+03, 6.50149764e-01] \n",
    "var_training_data = [1.25303578e-01, 1.16898690e-03, 2.86060835e+06, 1.64515717e+06, 6.85728371e+06, 3.63196175e+05, 8.21463343e-03]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from Artifical Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data= [-5.31764899e-02, -3.98576146e-04, -8.82773455e+05,  8.25672897e+02, 1.47034247e+04,  1.42685595e+03,  6.62155736e-01,  1.23172374e-02]\n",
    "var_training_data = [1.28792583e-01, 1.21258617e-03, 2.90245238e+06, 1.72279458e+06, 6.83095901e+06, 3.12357562e+05, 3.89033076e-03, 5.01164766e+01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Variance from phm Dataset\n",
    "droped features=[\"ongoing time\", \"up time\", \"RLU\", \"runnum\"] + <br>\n",
    "['FIXTURESHUTTERPOSITION_0.0','FIXTURESHUTTERPOSITION_1.0', 'FIXTURESHUTTERPOSITION_2.0', 'FIXTURESHUTTERPOSITION_3.0', <br>\n",
    "'FIXTURESHUTTERPOSITION_255.0', \"ETCHSOURCEUSAGE\", \"ETCHAUXSOURCETIMER\", \"ETCHAUX2SOURCETIMER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data =[ 0.0632522,0.10388593, 0.09563544, 0.0777276, 0.22081628, 0.08311531, 0.01382531,\n",
    "                     0.09862897, 0.07814727, -0.0185826, 0.1000127, -0.0161782, -0.22541928]\n",
    "var_training_data =[0.90316232, 0.97237671, 0.98547017, 0.92090347, 1.18086523, 0.92393987,\n",
    "                    0.41744699, 0.97142703, 0.92604794, 0.68786855, 1.25019607, 0.50023143, 0.69425608]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50.000 Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_training_data =[ 0.21683119,  0.32121513,  0.31925213,  0.20097501,  0.45164471,  0.22914814,\n",
    "  0.11604865,  0.27421592,  0.24393222, -0.13974937, -0.09739598, -0.07313758,\n",
    "  0.18198089]\n",
    "var_training_data =[0.75261122, 0.90482986, 0.91105327, 0.75504036, 1.07026701, 0.76708319,\n",
    " 0.35172769, 0.83004988, 0.76964675, 0.57386915, 0.45912309, 0.2955709,\n",
    " 1.61493449]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 14)\n"
     ]
    }
   ],
   "source": [
    "data_preperator = DataPreperatorPrediction(path=param['data']['path'], \n",
    "                                           ignored_features = param[\"data\"][\"droped_feature\"],\n",
    "                                           mean_training_data=mean_training_data, \n",
    "                                           var_training_data=var_training_data, \n",
    "                                           first_order_difference=False \n",
    "                                          )                                  \n",
    "preprocessed_data = data_preperator.prepare_data()\n",
    "print(preprocessed_data.shape)\n",
    "\n",
    "dataset = DataSet(preprocessed_data, \n",
    "                  timesteps=param[\"model\"][\"sequence_size\"])\n",
    "data_loader = DataLoader(dataset, \n",
    "                         batch_size=param['model']['batch_size'], \n",
    "                         num_workers=0, \n",
    "                         shuffle=False, \n",
    "                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data of batch: 0\n",
      "Size of input data: torch.Size([50, 100, 14])\n",
      "Size of target data: torch.Size([50, 14])\n",
      "Data of batch: 1\n",
      "Size of input data: torch.Size([50, 100, 14])\n",
      "Size of target data: torch.Size([50, 14])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(data_loader):\n",
    "    x,y = data\n",
    "    print('Data of batch: {}'.format(batch_idx))\n",
    "    print(\"Size of input data: {}\".format(x.size()))\n",
    "    print(\"Size of target data: {}\".format(y.size()))\n",
    "    if batch_idx >=1: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model and load Parameters of trained model\n",
    "### Model for MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmMse(batch_size=param['model']['batch_size'], \n",
    "                input_dim=param['model']['input_size'], \n",
    "                n_hidden_lstm=param['model']['n_hidden_lstm'], \n",
    "                n_hidden_fc=param['model']['n_hidden_fc'], \n",
    "                n_layers=param['model']['lstm_layer'], \n",
    "                dropout_rate_lstm= param['model']['dropout_rate_lstm'],\n",
    "                dropout_rate_fc= param['model']['dropout_rate_fc']\n",
    "                )\n",
    "\n",
    "checkpoint = torch.load(param[\"model\"][\"path\"])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LstmMle_1(batch_size=param['model']['batch_size'], \n",
    "                 input_dim=param['model']['input_size'], \n",
    "                 n_hidden_lstm=param['model']['n_hidden_lstm'], \n",
    "                 n_hidden_fc=param['model']['n_hidden_fc'], \n",
    "                 n_layers=param['model']['lstm_layer'], \n",
    "                 dropout_rate_lstm= param['model']['dropout_rate_lstm'],\n",
    "                 dropout_rate_fc= param['model']['dropout_rate_fc'],\n",
    "                 K = param['model']['K'])\n",
    "\n",
    "checkpoint = torch.load(param[\"model\"][\"path\"])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Latent Space Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmMultiTaskLearning(batch_size=param['model']['batch_size'], \n",
    "                              input_dim=param['model']['input_size'], \n",
    "                              n_hidden_lstm=param['model']['n_hidden_lstm'], \n",
    "                              n_layers=param['model']['lstm_layer'],\n",
    "                              dropout_rate_lstm= param['model']['dropout_rate_lstm'],\n",
    "                              dropout_rate_fc= param['model']['dropout_rate_fc'],\n",
    "                              n_hidden_fc_prediction=param['model']['n_hidden_fc_pred'], \n",
    "                              n_hidden_fc_ls_analysis=param['model']['n_hidden_fc_ls']      \n",
    "                              )\n",
    "\n",
    "checkpoint = torch.load(param[\"model\"][\"path\"])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Trainer\n",
    "### Predictor for MSE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PredictorMse(model=model,\n",
    "                         path_data=param[\"data\"][\"path\"],\n",
    "                         columns_to_ignore=param[\"data\"][\"droped_feature\"],\n",
    "                         threshold_anomaly=param[\"anomaly_detection\"][\"threshold_anomaly\"]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor for MLE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PredictorMle(model=model,\n",
    "                         path_data=param[\"data\"][\"path\"],\n",
    "                         columns_to_ignore=param[\"data\"][\"droped_feature\"],\n",
    "                         threshold_anomaly=param[\"anomaly_detection\"][\"threshold_anomaly\"],\n",
    "                         no_standard_deviation=param[\"anomaly_detection\"][\"no_standard_deviation\"]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor for Latent Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LstmMse_LatentSpace(model=model,\n",
    "                                path_data=param[\"data\"][\"path\"],\n",
    "                                columns_to_ignore=param[\"data\"][\"droped_feature\"],\n",
    "                                threshold_anomaly=param[\"anomaly_detection\"][\"threshold_anomaly\"]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting.\n",
      "Current status: 0 samples are predicted.\n",
      "Current status: 5000 samples are predicted.\n",
      "Current status: 10000 samples are predicted.\n",
      "Current status: 15000 samples are predicted.\n",
      "Current status: 20000 samples are predicted.\n",
      "Current status: 25000 samples are predicted.\n",
      "Current status: 30000 samples are predicted.\n",
      "Current status: 35000 samples are predicted.\n",
      "Current status: 40000 samples are predicted.\n",
      "Current status: 45000 samples are predicted.\n",
      "Current status: 50000 samples are predicted.\n",
      "Current status: 55000 samples are predicted.\n",
      "Current status: 60000 samples are predicted.\n",
      "Current status: 65000 samples are predicted.\n",
      "Current status: 70000 samples are predicted.\n",
      "Current status: 75000 samples are predicted.\n",
      "Current status: 80000 samples are predicted.\n",
      "Current status: 85000 samples are predicted.\n",
      "Current status: 90000 samples are predicted.\n",
      "Current status: 95000 samples are predicted.\n",
      "End of prediction.\n"
     ]
    }
   ],
   "source": [
    "print(\"Start predicting.\")\n",
    "# Write header\n",
    "with open(param[\"results\"][\"path\"], \"a+\") as file:\n",
    "            [file.write(column+\";\") for column in predictor.create_column_names_result()]\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "for batch_number, (input_data, target_data) in enumerate(data_loader):\n",
    "    # Predict sensor values in mini-batches\n",
    "    batch_results = predictor.predict(input_data, target_data)\n",
    "    \n",
    "    # Write results to csv file\n",
    "    with open(param[\"results\"][\"path\"], \"a\") as file:\n",
    "        for batch in batch_results:\n",
    "            # Each result component of a singe prediction (ID, target, prediction, loss, latent space ...) is stored in lists\n",
    "            # thus we have to unpack the list and seperate values with ;\n",
    "            for value in batch:\n",
    "                file.write(str(value)+\";\")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "    # Print status \n",
    "    if (batch_number*param['model']['batch_size'])%5000 == 0:\n",
    "        print(\"Current status: \" + str(param['model']['batch_size']*batch_number) + \" samples are predicted.\")\n",
    "\n",
    "print(\"End of prediction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag anomalous samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prediction = pd.read_csv(param[\"results\"][\"path\"], sep=\";\")\n",
    "# Values of column \"loss\" are exponentially smoothed and stored in a new column \"smoothed loss\"\n",
    "# New column \"anomaly\" is created and sample is taged with 1 if anomalous behaviour (if smoothed loss is over threshold)\n",
    "results = predictor.detect_anomaly(results_prediction, param[\"anomaly_detection\"][\"smooth_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>IONGAUGEPRESSURE target</th>\n",
       "      <th>ETCHBEAMVOLTAGE target</th>\n",
       "      <th>ETCHBEAMCURRENT target</th>\n",
       "      <th>ETCHSUPPRESSORVOLTAGE target</th>\n",
       "      <th>ETCHSUPPRESSORCURRENT target</th>\n",
       "      <th>FLOWCOOLFLOWRATE target</th>\n",
       "      <th>FLOWCOOLPRESSURE target</th>\n",
       "      <th>ETCHGASCHANNEL1READBACK target</th>\n",
       "      <th>ETCHPBNGASREADBACK target</th>\n",
       "      <th>...</th>\n",
       "      <th>Anomaly Sensor_4</th>\n",
       "      <th>Anomaly Sensor_5</th>\n",
       "      <th>Anomaly Sensor_6</th>\n",
       "      <th>Anomaly Sensor_7</th>\n",
       "      <th>Anomaly Sensor_8</th>\n",
       "      <th>Anomaly Sensor_9</th>\n",
       "      <th>Anomaly Sensor_10</th>\n",
       "      <th>Anomaly Sensor_11</th>\n",
       "      <th>Anomaly Sensor_12</th>\n",
       "      <th>Anomaly Sensor_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>-0.532284</td>\n",
       "      <td>-0.260403</td>\n",
       "      <td>1.399265</td>\n",
       "      <td>-0.116981</td>\n",
       "      <td>0.520474</td>\n",
       "      <td>0.517275</td>\n",
       "      <td>0.114534</td>\n",
       "      <td>0.547969</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>-0.532284</td>\n",
       "      <td>-0.262739</td>\n",
       "      <td>1.398483</td>\n",
       "      <td>-0.118881</td>\n",
       "      <td>0.520474</td>\n",
       "      <td>0.520695</td>\n",
       "      <td>0.109763</td>\n",
       "      <td>0.560713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>-0.532127</td>\n",
       "      <td>-0.260403</td>\n",
       "      <td>1.398370</td>\n",
       "      <td>-0.116027</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>0.520695</td>\n",
       "      <td>0.109763</td>\n",
       "      <td>0.560713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>-0.532127</td>\n",
       "      <td>-0.262597</td>\n",
       "      <td>1.398257</td>\n",
       "      <td>-0.117616</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>0.517275</td>\n",
       "      <td>0.109763</td>\n",
       "      <td>0.560713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105.0</td>\n",
       "      <td>0.316531</td>\n",
       "      <td>-0.531888</td>\n",
       "      <td>-0.261818</td>\n",
       "      <td>1.398483</td>\n",
       "      <td>-0.116027</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>0.521393</td>\n",
       "      <td>0.111100</td>\n",
       "      <td>0.563264</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  IONGAUGEPRESSURE target  ETCHBEAMVOLTAGE target  \\\n",
       "0  101.0                 0.316531               -0.532284   \n",
       "1  102.0                 0.316531               -0.532284   \n",
       "2  103.0                 0.316531               -0.532127   \n",
       "3  104.0                 0.316531               -0.532127   \n",
       "4  105.0                 0.316531               -0.531888   \n",
       "\n",
       "   ETCHBEAMCURRENT target  ETCHSUPPRESSORVOLTAGE target  \\\n",
       "0               -0.260403                      1.399265   \n",
       "1               -0.262739                      1.398483   \n",
       "2               -0.260403                      1.398370   \n",
       "3               -0.262597                      1.398257   \n",
       "4               -0.261818                      1.398483   \n",
       "\n",
       "   ETCHSUPPRESSORCURRENT target  FLOWCOOLFLOWRATE target  \\\n",
       "0                     -0.116981                 0.520474   \n",
       "1                     -0.118881                 0.520474   \n",
       "2                     -0.116027                 0.521334   \n",
       "3                     -0.117616                 0.521334   \n",
       "4                     -0.116027                 0.521334   \n",
       "\n",
       "   FLOWCOOLPRESSURE target  ETCHGASCHANNEL1READBACK target  \\\n",
       "0                 0.517275                        0.114534   \n",
       "1                 0.520695                        0.109763   \n",
       "2                 0.520695                        0.109763   \n",
       "3                 0.517275                        0.109763   \n",
       "4                 0.521393                        0.111100   \n",
       "\n",
       "   ETCHPBNGASREADBACK target  ...  Anomaly Sensor_4  Anomaly Sensor_5  \\\n",
       "0                   0.547969  ...                 0                 0   \n",
       "1                   0.560713  ...                 0                 0   \n",
       "2                   0.560713  ...                 0                 0   \n",
       "3                   0.560713  ...                 0                 0   \n",
       "4                   0.563264  ...                 0                 0   \n",
       "\n",
       "   Anomaly Sensor_6  Anomaly Sensor_7  Anomaly Sensor_8  Anomaly Sensor_9  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "   Anomaly Sensor_10  Anomaly Sensor_11  Anomaly Sensor_12  Anomaly Sensor_13  \n",
       "0                  0                  0                  0                  0  \n",
       "1                  0                  0                  0                  0  \n",
       "2                  0                  0                  0                  0  \n",
       "3                  0                  0                  0                  0  \n",
       "4                  0                  0                  0                  0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine prediction data with data which was not consider for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sensor_data = pd.read_csv(param[\"data\"][\"path\"])\n",
    "data_of_droped_feature = original_sensor_data.loc[:, param[\"data\"][\"droped_feature\"]+[\"ID\"]]\n",
    "complete_data = results.merge(right=data_of_droped_feature, how=\"inner\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.to_csv(param[\"results\"][\"path\"], sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
