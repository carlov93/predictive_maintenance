{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# own Modules \n",
    "from models.models import LstmMse\n",
    "from utils.data_loader import DataPreperatorPrediction, DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam = {\n",
    "    \"data\" : {\n",
    "        \"stake_training_data\" : 0.75, \n",
    "        \"path_new\" : '../../data/vega_shrinkwrapper_original/NewBlade/', \n",
    "        \"path_worn\" : '../../data/vega_shrinkwrapper_original/WornBlade/'\n",
    "    },\n",
    "    \"model\" : {\n",
    "        \"input_size\" : 7,\n",
    "        \"n_hidden\" : 150,\n",
    "        \"sequence_size\" : 50,\n",
    "        \"batch_size\" : 1,\n",
    "        \"lstm_layer\" : 3,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict new blade data\n",
    "## Standarize Validation Data\n",
    "First we have to apply normalisation to data. That is because the model works on the representation given by its input vectors. The scale of those numbers is part of the representation.\n",
    "We should apply the exact same scaling as for training data. That means storing the scale and offset used with your training data, and using that again. <br>\n",
    "__The mean and variance for each feature of the training data with which the model was trained (stake: 0.75):__\n",
    "\n",
    "```python\n",
    "mean_training_data = [-5.37536613e-02, -2.53111489e-04, -8.82854465e+05, 7.79034183e+02,1.45531178e+04, 1.37766733e+03, 6.50149764e-01]\n",
    "variance_training_data = [1.25303578e-01, 1.16898690e-03, 2.86060835e+06, 1.64515717e+06, 6.85728371e+06, 3.63196175e+05, 8.21463343e-03]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and scale training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_blade_loader = DataPreperatorPrediction(path=hyperparam['data']['path_new']+'NewBlade001.csv')\n",
    "preprocessed_new_blade = new_blade_loader.provide_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load worn blade dataset and scale them with mean and variance of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "worn_blade_loader = DataPreperatorPrediction(path=hyperparam['data']['path_worn']+'WornBlade001.csv')\n",
    "preprocessed_worn_blade = worn_blade_loader.provide_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_worn_blade = DataSet(preprocessed_worn_blade, timesteps=50)\n",
    "dataset_new_blade = DataSet(preprocessed_new_blade, timesteps=50)\n",
    "\n",
    "data_loader_worn_blade = DataLoader(dataset_worn_blade, batch_size=1, num_workers=1, shuffle=False, drop_last=True)\n",
    "data_loader_new_blade = DataLoader(dataset_new_blade, batch_size=1, num_workers=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new blade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlovoss/jupyter_notebooks/masterarbeit/venv_pm/lib/python3.6/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Initiate and load model\n",
    "model = LstmMse(batch_size=hyperparam['model']['batch_size'], input_dim=hyperparam['model']['input_size'], \n",
    "             n_hidden=hyperparam['model']['n_hidden'], n_layers=hyperparam['model']['lstm_layer'])\n",
    "\n",
    "PATH = \"../../models/MSE_model/best_model_aws_tanh.pt\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Create empty dataframe\n",
    "columns = [\"timestamp\", \"cut_torque_target\", \"cut_lag error_target\", \"cut_position_target\", \"cut_speed_target\", \n",
    "           \"film_position_target\", \"film_speed_target\", \"film_lag_error_target\", \"cut_torque_predicted\", \n",
    "           \"cut_lag error_predicted\", \"cut_position_predicted\", \"cut_speed_predicted\", \"film_position_predicted\", \n",
    "           \"film_speed_predicted\", \"film_lag_error_predicted\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "print(\"Start predicting\")    \n",
    "##### Predict #####\n",
    "for batch_number, data in enumerate(data_loader_new_blade):\n",
    "    \n",
    "    input_data, target_data = data\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    # Forward propagation\n",
    "    output = model(input_data, hidden)\n",
    "    \n",
    "    # Add values to dataframe \n",
    "    output = torch.squeeze(output)\n",
    "    target_data = torch.squeeze(target_data)\n",
    "    target_data_np = target_data.data.numpy().tolist()\n",
    "    predicted_data_np = output.data.numpy().tolist()\n",
    "    data = [batch_number] + target_data_np + predicted_data_np\n",
    "    df = df.append(pd.Series(data, index=df.columns ), ignore_index=True)\n",
    "\n",
    "# Save dataframe as csv file\n",
    "df.to_csv(\"../visualisation/files/prediction_new_blade_tanh.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"Finished\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict worn blade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Initiate and load model\n",
    "model = LstmMse(batch_size=hyperparam['model']['batch_size'], input_dim=hyperparam['model']['input_size'], \n",
    "             n_hidden=hyperparam['model']['n_hidden'], n_layers=hyperparam['model']['lstm_layer'])\n",
    "\n",
    "PATH = \"../../models/MSE_model/best_model_aws.pt\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Create empty dataframe\n",
    "columns = [\"timestamp\", \"cut_torque_target\", \"cut_lag error_target\", \"cut_position_target\", \"cut_speed_target\", \n",
    "           \"film_position_target\", \"film_speed_target\", \"film_lag_error_target\", \"cut_torque_predicted\", \n",
    "           \"cut_lag error_predicted\", \"cut_position_predicted\", \"cut_speed_predicted\", \"film_position_predicted\", \n",
    "           \"film_speed_predicted\", \"film_lag_error_predicted\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "print(\"Start predicting\")    \n",
    "##### Predict #####\n",
    "for batch_number, data in enumerate(data_loader_worn_blade):\n",
    "    \n",
    "    input_data, target_data = data\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    # Forward propagation\n",
    "    output = model(input_data, hidden)\n",
    "    \n",
    "    # Add values to dataframe \n",
    "    output = torch.squeeze(output)\n",
    "    target_data = torch.squeeze(target_data)\n",
    "    target_data_np = target_data.data.numpy().tolist()\n",
    "    predicted_data_np = output.data.numpy().tolist()\n",
    "    data = [batch_number] + target_data_np + predicted_data_np\n",
    "    df = df.append(pd.Series(data, index=df.columns ), ignore_index=True)\n",
    "\n",
    "# Save dataframe as csv file\n",
    "df.to_csv(\"../visualisation/files/prediction_worn_blade.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"Finished\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
