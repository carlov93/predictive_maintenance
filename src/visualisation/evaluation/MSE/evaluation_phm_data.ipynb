{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_anomaly_detection(dataframe, no_features, first_feature, last_feature, failures, line, training):\n",
    "    fig, axes = plt.subplots(no_features, 1, figsize=(30,40))\n",
    "    ax = axes.ravel()\n",
    "    columns = dataframe.columns\n",
    "    t = dataframe[\"up time\"]\n",
    "    for i in range(first_feature, last_feature):\n",
    "        sns.lineplot(data=dataframe, \n",
    "                     x=t, \n",
    "                     y=dataframe.iloc[:, i+3*no_features].cumsum(),\n",
    "                     ax=ax[i-first_feature],\n",
    "                     color=\"blue\",)\n",
    "        \n",
    "        # Plot line for last training sample\n",
    "        if training:\n",
    "            ax[i-1].axvspan(3283834,3523830, alpha=0.2, color='green')\n",
    "        \n",
    "        # Plot line for failure points\n",
    "        if line:\n",
    "            for failure in failures:\n",
    "                ax[i-first_feature].axvline(failure, 0,2, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        \n",
    "        # Set y-limit\n",
    "        ax[i-first_feature].set_ylim(0,15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(data_frame, score_type, no_sensors):\n",
    "    \"\"\"\n",
    "    :param data_frame: Complete Dataframe\n",
    "    :param no_sensors: Number of Sensors in Dataframe\n",
    "    :param start_time: Start point. Value from time column\n",
    "    :param max_delta: Number of samples. max_time = (no_samples * (time between two samples))\n",
    "    :param step_size: It is the number of samples added to current time_delta to get next time_delta\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    labels_pred = data_frame.iloc[:, (3 * no_sensors) + 1:(4 * no_sensors) + 1]\n",
    "    labels_true = data_frame[\"status\"].values\n",
    "    \n",
    "    result_score = np.zeros((no_sensors))\n",
    "\n",
    "    for sensor in range(no_sensors):\n",
    "        anomaly_pred = labels_pred.iloc[:, sensor].values\n",
    "        if score_type == \"f1_score\":\n",
    "            result = f1_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"f1 sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        elif score_type == \"precision_score\":\n",
    "            result = precision_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"precision sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        elif score_type == \"recall_score\":\n",
    "            result = recall_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"recall sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        else:\n",
    "            result = 0\n",
    "            index_names = [\"error\" for i in range(no_sensors)]\n",
    "            \n",
    "        result_score[sensor] = result\n",
    "\n",
    "    score_df = pd.Series(data=result_score, index=index_names)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_metric_per_sensor(results, title):\n",
    "    fig, axes = plt.subplots(results.shape[1]-1, 1, figsize=(10,20),constrained_layout=False)\n",
    "    ax = axes.ravel()\n",
    "    t = results.loc[:,\"delta_t\"]\n",
    "    columns = results.columns\n",
    "    for i in range(results.shape[1]-1): \n",
    "        sns.lineplot(data=results, \n",
    "                     x=t, \n",
    "                     y=columns[i], \n",
    "                     ax=ax[i],\n",
    "                     linewidth=1,\n",
    "                     color=\"black\")\n",
    "        ax[i].set_xlabel(\"delta t [in samples]\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.suptitle(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_metric_machine(results, score_type, phase):\n",
    "    t = results.loc[:,\"delta_t\"]\n",
    "    complete_title = \"CPPS Data - Beginning of Phase '{}''\".format(phase)\n",
    "    \n",
    "    # Caluculate Metric for hole machine (sum over sensors and devide by no_sensors)\n",
    "    labels = results.drop(columns=\"delta_t\", axis=0)\n",
    "    results_machine = labels.sum(axis=1) / results.shape[1]\n",
    "    \n",
    "    # Visualise Results\n",
    "    sns.lineplot(x=t, \n",
    "                 y=results_machine, \n",
    "                 linewidth=1,\n",
    "                 color=\"black\")\n",
    "    plt.xlabel(\"delta t [in samples]\")\n",
    "    plt.ylabel(\"{} over all dim\".format(score_type))\n",
    "    #plt.tight_layout()\n",
    "    plt.title(complete_title, fontsize=16, y=1.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_cumulative_detection(dataframe, no_features, first_feature, last_feature, location_line1, location_line2, subset):\n",
    "    fig, axes = plt.subplots(subset, 1, figsize=(10,6), dpi=200)\n",
    "    ax = axes.ravel()\n",
    "    columns = dataframe.columns\n",
    "    t = dataframe.iloc[:,0]\n",
    "    for i in range(first_feature, last_feature):\n",
    "        sns.lineplot(data=dataframe, \n",
    "                     x=t, \n",
    "                     y=dataframe.iloc[:, i+3*no_features].cumsum(),\n",
    "                     ax=ax[i-first_feature],\n",
    "                     color=\"blue\",)\n",
    "        ax[i-first_feature].axvline(location_line1, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        ax[i-first_feature].axvline(location_line2, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        ax[i-first_feature].text(7000, 14000, \"Phase 1: No Error\", fontsize=10)\n",
    "        ax[i-first_feature].text(25000, 14000, \"Phase 2: Small Error\", fontsize=10)\n",
    "        ax[i-first_feature].text(41000, 3000, \"Phase 3: Large Error\", fontsize=10)\n",
    "        \n",
    "        # Legend etc. \n",
    "        ax[i-1].set_xlabel(\"time [in s]\")\n",
    "        ax[i-1].set_ylabel(\"Cumulative sum\")\n",
    "        ax[i-1].set_title(\"Sensor No.{}\".format(i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_machine(data_frame, no_sensors):\n",
    "    \n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    for i in range(0,no_sensors):\n",
    "        labels_pred = data_frame.iloc[:, (3 * no_sensors)+i+1].values\n",
    "        labels_true = data_frame[\"status\"].values\n",
    "        \n",
    "        tn_sensor, fp_sensor, fn_sensor, tp_sensor = confusion_matrix(labels_true, labels_pred).ravel()\n",
    "        tp.append(tp_sensor)\n",
    "        fp.append(fp_sensor)\n",
    "        tn.append(tn_sensor)\n",
    "        fn.append(fn_sensor)\n",
    "    \n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of Sensors\n",
    "name_of_sensor = [\"IONGAUGEPRESSURE\",\n",
    "                  \"ETCHBEAMVOLTAGE\",\n",
    "                  \"ETCHBEAMCURRENT\",\n",
    "                  \"ETCHSUPPRESSORVOLTAGE\",\n",
    "                  \"ETCHSUPPRESSORCURRENT\",\n",
    "                  \"FLOWCOOLFLOWRATE\",\n",
    "                  \"FLOWCOOLPRESSURE\",\n",
    "                  \"ETCHGASCHANNEL1READBACK\",\n",
    "                  \"ETCHPBNGASREADBACK\",\n",
    "                  \"FIXTURETILTANGLE\",\n",
    "                  \"ACTUALROTATIONANGLE\",\n",
    "                  \"ACTUALSTEPDURATION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../../files/classification/MSE/phm67_max_minus_60percent.csv\", sep=\";\")\n",
    "until_first_failure = all_data.loc[all_data[\"up time\"]<=3807966]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_failures_67 =[3807966., 3814610., 3815890., 3816362., 3856686., 3860122., 3865202., 3867646., 3868170.,\n",
    "       3870094., 6539522., 6549554., 6572426., 6573162., 6574566., 6575118., 6575566., 6577254., 6582502., 6586022.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3335278669390137\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(until_first_failure, \"f1_score\", 12)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive --> Anomaly\n",
      "Negative --> Normal Behaviour\n",
      "------------------------------\n",
      "True negative: 56643\n",
      "False positive: 800\n",
      "False negative: 8336\n",
      "True positive: 2286\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive --> Anomaly\")\n",
    "print(\"Negative --> Normal Behaviour\")\n",
    "print(\"--\"*15)\n",
    "tp, fp, tn, fn = get_confusion_matrix_machine(until_first_failure, 12)\n",
    "print(\"True negative: {}\".format(tn[0]))\n",
    "print(\"False positive: {}\".format(fp[0]))\n",
    "print(\"False negative: {}\".format(fn[0]))\n",
    "print(\"True positive: {}\".format(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9860731507755515\n"
     ]
    }
   ],
   "source": [
    "print(tn[0] / (tn[0] + fp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Sum of Anomaly, labeld by LSTM-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1 = artifical_data.iloc[0:75000,:]\n",
    "failures_67_subset1 =[3807966., 3814610., 3815890., 3816362., 3856686., 3860122., 3865202., 3867646., 3868170., 3870094.]\n",
    "vis_anomaly_detection(subset_1, 12, 1, 13, failures_67_subset1, line=True, training=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_2 = artifical_data.iloc[90000:150000,:]\n",
    "vis_anomaly_detection(subset_2, 12, 1, 13, failures_67_subset1, line=False, training=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_5 = artifical_data.iloc[380000:425000,:]\n",
    "failures_67_subset5 =[6539522., 6549554., 6572426., 6573162., 6574566., 6575118., 6575566., 6577254., 6582502., 6586022.]\n",
    "vis_anomaly_detection(subset_5, 12, 1, 13, failures_67_subset5, line=True, training=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
