{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(data_frame, score_type, no_sensors):\n",
    "    \"\"\"\n",
    "    :param data_frame: Complete Dataframe\n",
    "    :param no_sensors: Number of Sensors in Dataframe\n",
    "    :param start_time: Start point. Value from time column\n",
    "    :param max_delta: Number of samples. max_time = (no_samples * (time between two samples))\n",
    "    :param step_size: It is the number of samples added to current time_delta to get next time_delta\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    labels_pred = data_frame.iloc[:, (4 * no_sensors) + 2:(5 * no_sensors) + 2]\n",
    "    labels_true = data_frame[\"status\"].values\n",
    "    \n",
    "    result_score = np.zeros((no_sensors))\n",
    "\n",
    "    for sensor in range(no_sensors):\n",
    "        anomaly_pred = labels_pred.iloc[:, sensor].values\n",
    "        if score_type == \"f1_score\":\n",
    "            result = f1_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"f1 sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        elif score_type == \"precision_score\":\n",
    "            result = precision_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"precision sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        elif score_type == \"recall_score\":\n",
    "            result = recall_score(labels_true, anomaly_pred, average=\"binary\")\n",
    "            index_names = [\"recall sensor_\" + str(i) for i in range(no_sensors)]\n",
    "        else:\n",
    "            result = 0\n",
    "            index_names = [\"error\" for i in range(no_sensors)]\n",
    "            \n",
    "        result_score[sensor] = result\n",
    "\n",
    "    score_df = pd.Series(data=result_score, index=index_names)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_metric_per_sensor(results, title):\n",
    "    fig, axes = plt.subplots(results.shape[1]-1, 1, figsize=(10,20),constrained_layout=False)\n",
    "    ax = axes.ravel()\n",
    "    t = results.loc[:,\"delta_t\"]\n",
    "    columns = results.columns\n",
    "    for i in range(results.shape[1]-1): \n",
    "        sns.lineplot(data=results, \n",
    "                     x=t, \n",
    "                     y=columns[i], \n",
    "                     ax=ax[i],\n",
    "                     linewidth=1,\n",
    "                     color=\"black\")\n",
    "        ax[i].set_xlabel(\"delta t [in samples]\")\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.suptitle(title, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_metric_machine(results, score_type, phase):\n",
    "    t = results.loc[:,\"delta_t\"]\n",
    "    complete_title = \"CPPS Data - Beginning of Phase '{}''\".format(phase)\n",
    "    \n",
    "    # Caluculate Metric for hole machine (sum over sensors and devide by no_sensors)\n",
    "    labels = results.drop(columns=\"delta_t\", axis=0)\n",
    "    result_machine = labels.sum(axis=1) / results.shape[1]\n",
    "    \n",
    "    # Visualise Results\n",
    "    sns.lineplot(x=t, \n",
    "                 y=result_machine, \n",
    "                 linewidth=1,\n",
    "                 color=\"black\")\n",
    "    plt.xlabel(\"delta t [in samples]\")\n",
    "    plt.ylabel(\"{} over all dim\".format(score_type))\n",
    "    #plt.tight_layout()\n",
    "    plt.title(complete_title, fontsize=16, y=1.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_cumulative_detection(dataframe, no_features, first_feature, last_feature, location_line1, location_line2, subset):\n",
    "    fig, axes = plt.subplots(subset, 1, figsize=(10,6), dpi=200)\n",
    "    ax = axes.ravel()\n",
    "    columns = dataframe.columns\n",
    "    t = dataframe.iloc[:,0]\n",
    "    for i in range(first_feature, last_feature):\n",
    "        sns.lineplot(data=dataframe, \n",
    "                     x=t, \n",
    "                     y=dataframe.iloc[:, i+4*no_features+1].cumsum(),\n",
    "                     ax=ax[i-first_feature],\n",
    "                     color=\"blue\",)\n",
    "        ax[i-first_feature].set_ylim(0, 5000) \n",
    "        ax[i-first_feature].axvline(location_line1, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        ax[i-first_feature].axvline(location_line2, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        ax[i-first_feature].text(7000, 4000, \"Phase 1: No Error\", fontsize=10)\n",
    "        ax[i-first_feature].text(25000, 4000, \"Phase 2: Small Error\", fontsize=10)\n",
    "        ax[i-first_feature].text(41000, 1000, \"Phase 3: Large Error\", fontsize=10)\n",
    "        \n",
    "        # Legend etc. \n",
    "        ax[i-1].set_xlabel(\"time [in s]\")\n",
    "        ax[i-1].set_ylabel(\"Cumulative sum\")\n",
    "        ax[i-1].set_title(\"Sensor No.{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_machine(data_frame, no_sensors):\n",
    "    \n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    for i in range(0,no_sensors):\n",
    "        labels_pred = data_frame.iloc[:, (4 * no_sensors)+i+2].values\n",
    "        labels_true = data_frame[\"status\"].values\n",
    "        \n",
    "        tn_sensor, fp_sensor, fn_sensor, tp_sensor = confusion_matrix(labels_true, labels_pred).ravel()\n",
    "        tp.append(tp_sensor)\n",
    "        fp.append(fp_sensor)\n",
    "        tn.append(tn_sensor)\n",
    "        fn.append(fn_sensor)\n",
    "    \n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_anomaly_detection(dataframe, no_features, first_feature, last_feature, failures, line, training):\n",
    "    fig, axes = plt.subplots(no_features, 1, figsize=(30,40))\n",
    "    ax = axes.ravel()\n",
    "    columns = dataframe.columns\n",
    "    t = dataframe[\"up time\"]\n",
    "    for i in range(first_feature, last_feature):\n",
    "        sns.lineplot(data=dataframe, \n",
    "                     x=t, \n",
    "                     y=dataframe.iloc[:, i+4*no_features+1].cumsum(),\n",
    "                     ax=ax[i-first_feature],\n",
    "                     color=\"blue\",)\n",
    "        \n",
    "        # Plot line for last training sample\n",
    "        if training:\n",
    "            ax[i-1].axvspan(3283834,3523830, alpha=0.2, color='green')\n",
    "        \n",
    "        # Plot line for failure points\n",
    "        if line:\n",
    "            for failure in failures:\n",
    "                ax[i-first_feature].axvline(failure, 0,2, color=\"r\", linestyle =\"--\", linewidth=2)\n",
    "        \n",
    "        # Set y-limit\n",
    "        ax[i-first_feature].set_ylim(0,15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Prediction Interval\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_A1 = pd.read_csv(\"../../files/classification/MLE/2_research_question/phm67_2sigma_A1.csv\", sep=\";\")\n",
    "until_first_failure_A1 = all_data_A1.loc[all_data_A1[\"up time\"]<=3807966]\n",
    "all_data_A2 = pd.read_csv(\"../../files/classification/MLE/2_research_question/phm67_2sigma_A2.csv\", sep=\";\")\n",
    "until_first_failure_A2 = all_data_A2.loc[all_data_A2[\"up time\"]<=3807966]\n",
    "all_data_A3 = pd.read_csv(\"../../files/classification/MLE/2_research_question/phm67_2sigma_A3.csv\", sep=\";\")\n",
    "until_first_failure_A3 = all_data_A3.loc[all_data_A3[\"up time\"]<=3807966]\n",
    "all_data_A4 = pd.read_csv(\"../../files/classification/MLE/2_research_question/phm67_2sigma_A4.csv\", sep=\";\")\n",
    "until_first_failure_A4 = all_data_A4.loc[all_data_A4[\"up time\"]<=3807966]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Architecture 1\n",
    "### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7035222180340913\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(until_first_failure_A1, \"f1_score\", 12)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive --> Anomaly\n",
      "Negative --> Normal Behaviour\n",
      "------------------------------\n",
      "True negative: 52600\n",
      "False positive: 4856\n",
      "False negative: 2223\n",
      "True positive: 8399\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive --> Anomaly\")\n",
    "print(\"Negative --> Normal Behaviour\")\n",
    "print(\"--\"*15)\n",
    "tp, fp, tn, fn = get_confusion_matrix_machine(until_first_failure_A1, 12)\n",
    "print(\"True negative: {}\".format(tn[0]))\n",
    "print(\"False positive: {}\".format(fp[0]))\n",
    "print(\"False negative: {}\".format(fn[0]))\n",
    "print(\"True positive: {}\".format(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154831523252576\n"
     ]
    }
   ],
   "source": [
    "print(tn[0] / (tn[0] + fp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Architecture 2\n",
    "### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6649087922538255\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(until_first_failure_A2, \"f1_score\", 12)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive --> Anomaly\n",
      "Negative --> Normal Behaviour\n",
      "------------------------------\n",
      "True negative: 52635\n",
      "False positive: 4821\n",
      "False negative: 2931\n",
      "True positive: 7691\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive --> Anomaly\")\n",
    "print(\"Negative --> Normal Behaviour\")\n",
    "print(\"--\"*15)\n",
    "tp, fp, tn, fn = get_confusion_matrix_machine(until_first_failure_A2, 12)\n",
    "print(\"True negative: {}\".format(tn[0]))\n",
    "print(\"False positive: {}\".format(fp[0]))\n",
    "print(\"False negative: {}\".format(fn[0]))\n",
    "print(\"True positive: {}\".format(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9160923141186299\n"
     ]
    }
   ],
   "source": [
    "print(tn[0] / (tn[0] + fp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Architecture 3\n",
    "### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6996761896954543\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(until_first_failure_A3, \"f1_score\", 12)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive --> Anomaly\n",
      "Negative --> Normal Behaviour\n",
      "------------------------------\n",
      "True negative: 52216\n",
      "False positive: 5240\n",
      "False negative: 2087\n",
      "True positive: 8535\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive --> Anomaly\")\n",
    "print(\"Negative --> Normal Behaviour\")\n",
    "print(\"--\"*15)\n",
    "tp, fp, tn, fn = get_confusion_matrix_machine(until_first_failure_A3, 12)\n",
    "print(\"True negative: {}\".format(tn[0]))\n",
    "print(\"False positive: {}\".format(fp[0]))\n",
    "print(\"False negative: {}\".format(fn[0]))\n",
    "print(\"True positive: {}\".format(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9087997772208298\n"
     ]
    }
   ],
   "source": [
    "print(tn[0] / (tn[0] + fp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Architecture 4\n",
    "### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6648757555406313\n"
     ]
    }
   ],
   "source": [
    "score = calculate_score(until_first_failure_A4, \"f1_score\", 12)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive --> Anomaly\n",
      "Negative --> Normal Behaviour\n",
      "------------------------------\n",
      "True negative: 53168\n",
      "False positive: 4288\n",
      "False negative: 3197\n",
      "True positive: 7425\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive --> Anomaly\")\n",
    "print(\"Negative --> Normal Behaviour\")\n",
    "print(\"--\"*15)\n",
    "tp, fp, tn, fn = get_confusion_matrix_machine(until_first_failure_A4, 12)\n",
    "print(\"True negative: {}\".format(tn[0]))\n",
    "print(\"False positive: {}\".format(fp[0]))\n",
    "print(\"False negative: {}\".format(fn[0]))\n",
    "print(\"True positive: {}\".format(tp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensetivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925368978000557\n"
     ]
    }
   ],
   "source": [
    "print(tn[0] / (tn[0] + fp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterarbeit",
   "language": "python",
   "name": "masterarbeit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
