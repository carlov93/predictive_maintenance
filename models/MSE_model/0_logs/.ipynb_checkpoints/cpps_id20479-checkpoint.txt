Architecture and Training configuration:
Loss function: MSE
Batch size: 8
Input size: 10
Sequence length: 21
Hidden units LSTM: 13
Amount LSTM layer: 1
Dropout rate LSTM: 0.0
Dropout rate fc NN: 0.2
Hidden units fc: 55
Cycling LR mode: triangular
Cycling LR base LR: 0.0001
Cycling LR max LR: 0.0005
- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -
Training phase is started
-------- epoch_no. 0 finished with training loss 0.6608619826856668--------
-------- epoch_no. 1 finished with training loss 0.4677074262751857--------
-------- epoch_no. 2 finished with training loss 0.37457183266376637--------
-------- epoch_no. 3 finished with training loss 0.3221624149294223--------
-------- epoch_no. 4 finished with training loss 0.288540575003437--------
-------- epoch_no. 5 finished with training loss 0.2641126929007032--------
-------- epoch_no. 6 finished with training loss 0.24522218320362452--------
-------- epoch_no. 7 finished with training loss 0.23045219384771765--------
-------- epoch_no. 8 finished with training loss 0.21866216737461333--------
-------- epoch_no. 9 finished with training loss 0.20894887199592843--------
-------- epoch_no. 10 finished with training loss 0.20071469728237887--------
-------- epoch_no. 11 finished with training loss 0.19366760186438575--------
-------- epoch_no. 12 finished with training loss 0.18756899823159304--------
-------- epoch_no. 13 finished with training loss 0.18224664863291595--------
-------- epoch_no. 14 finished with training loss 0.1774895576464993--------
-------- epoch_no. 15 finished with training loss 0.17319662722007897--------
-------- epoch_no. 16 finished with training loss 0.1693378626131166--------
-------- epoch_no. 17 finished with training loss 0.16584208454160038--------
-------- epoch_no. 18 finished with training loss 0.16265551898139063--------
-------- epoch_no. 19 finished with training loss 0.15972223651808062--------
-------- epoch_no. 20 finished with training loss 0.15703513490449553--------
-------- epoch_no. 21 finished with training loss 0.1545771181597479--------
-------- epoch_no. 22 finished with training loss 0.15229523353957733--------
-------- epoch_no. 23 finished with training loss 0.1501906641876498--------
-------- epoch_no. 24 finished with training loss 0.14824090574560794--------
-------- epoch_no. 25 finished with training loss 0.14642471632072107--------
Training phase is finished
- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -
Mean Reconstruction Error: [0.24372421389777016, 0.24761591192911026, 0.32903928384871034, 0.18159441767379658, 0.27133063146032477, 0.23155811781422755, 0.149805263381253, 0.31187742832928145, 0.0716386888894709, 0.2080102174959789]
Max Reconstruction Error: [3.6399233341217037, 3.062077760696411, 3.790999054908752, 3.4866878986358643, 4.062194585800172, 3.656018495559693, 3.338533520698548, 3.4780687093734737, 3.3930306434631348, 2.8501847982406616]
